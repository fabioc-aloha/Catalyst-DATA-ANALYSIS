{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db77703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rich datasets for advanced visualization\n",
    "print(\"üé® CREATING VISUALIZATION DATASETS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Dataset 1: Scientific research data\n",
    "np.random.seed(42)\n",
    "n_experiments = 1000\n",
    "\n",
    "research_data = {\n",
    "    'experiment_id': range(1, n_experiments + 1),\n",
    "    'treatment_group': np.random.choice(['Control', 'Treatment_A', 'Treatment_B', 'Treatment_C'], n_experiments),\n",
    "    'measurement_1': np.random.normal(50, 15, n_experiments),\n",
    "    'measurement_2': np.random.gamma(2, 10, n_experiments),\n",
    "    'measurement_3': np.random.exponential(5, n_experiments),\n",
    "    'confidence_score': np.random.beta(2, 5, n_experiments),\n",
    "    'lab_location': np.random.choice(['Lab_A', 'Lab_B', 'Lab_C', 'Lab_D'], n_experiments),\n",
    "    'researcher': np.random.choice(['Dr. Smith', 'Dr. Johnson', 'Dr. Williams', 'Dr. Brown'], n_experiments),\n",
    "    'date': pd.date_range(start='2024-01-01', periods=n_experiments, freq='H')\n",
    "}\n",
    "\n",
    "# Add correlations and interactions\n",
    "for i in range(n_experiments):\n",
    "    if research_data['treatment_group'][i] == 'Treatment_A':\n",
    "        research_data['measurement_1'][i] += 10\n",
    "    elif research_data['treatment_group'][i] == 'Treatment_B':\n",
    "        research_data['measurement_1'][i] += 20\n",
    "    elif research_data['treatment_group'][i] == 'Treatment_C':\n",
    "        research_data['measurement_1'][i] += 15\n",
    "\n",
    "# Create success/failure outcome based on measurements\n",
    "research_data['success'] = [\n",
    "    1 if (m1 > 60 and m2 > 15) else 0 \n",
    "    for m1, m2 in zip(research_data['measurement_1'], research_data['measurement_2'])\n",
    "]\n",
    "\n",
    "df_research = pd.DataFrame(research_data)\n",
    "\n",
    "# Dataset 2: Financial market data\n",
    "dates = pd.date_range(start='2023-01-01', end='2025-07-19', freq='D')\n",
    "n_days = len(dates)\n",
    "\n",
    "# Simulate stock prices with realistic volatility\n",
    "initial_price = 100\n",
    "prices = [initial_price]\n",
    "volumes = []\n",
    "\n",
    "for i in range(1, n_days):\n",
    "    # Random walk with slight upward trend\n",
    "    change = np.random.normal(0.001, 0.02)  # Small daily drift with volatility\n",
    "    new_price = prices[-1] * (1 + change)\n",
    "    prices.append(max(new_price, 0.01))  # Ensure positive prices\n",
    "    \n",
    "    # Volume correlated with price changes\n",
    "    volume = int(np.random.normal(1000000, 300000) * (1 + abs(change) * 10))\n",
    "    volumes.append(max(volume, 100000))\n",
    "\n",
    "# Add the final volume\n",
    "volumes.append(int(np.random.normal(1000000, 300000)))\n",
    "\n",
    "financial_data = {\n",
    "    'date': dates,\n",
    "    'price': prices,\n",
    "    'volume': volumes,\n",
    "    'sector': np.random.choice(['Technology', 'Healthcare', 'Finance', 'Energy', 'Consumer'], n_days),\n",
    "    'market_cap': [p * 1000000 for p in prices],  # Market cap in millions\n",
    "}\n",
    "\n",
    "# Technical indicators\n",
    "financial_data['sma_20'] = pd.Series(prices).rolling(window=20).mean().fillna(prices[0])\n",
    "financial_data['volatility'] = pd.Series(prices).pct_change().rolling(window=10).std().fillna(0.02)\n",
    "\n",
    "df_financial = pd.DataFrame(financial_data)\n",
    "\n",
    "# Dataset 3: Geographic sales data\n",
    "cities = [\n",
    "    ('New York', 40.7128, -74.0060, 8400000),\n",
    "    ('Los Angeles', 34.0522, -118.2437, 3900000),\n",
    "    ('Chicago', 41.8781, -87.6298, 2700000),\n",
    "    ('Houston', 29.7604, -95.3698, 2300000),\n",
    "    ('Phoenix', 33.4484, -112.0740, 1600000),\n",
    "    ('Philadelphia', 39.9526, -75.1652, 1500000),\n",
    "    ('San Antonio', 29.4241, -98.4936, 1400000),\n",
    "    ('San Diego', 32.7157, -117.1611, 1400000),\n",
    "    ('Dallas', 32.7767, -96.7970, 1300000),\n",
    "    ('San Jose', 37.3382, -121.8863, 1000000)\n",
    "]\n",
    "\n",
    "geographic_data = []\n",
    "for city, lat, lon, population in cities:\n",
    "    # Generate sales data for each city\n",
    "    base_sales = population * np.random.uniform(0.1, 0.3)  # Sales per capita\n",
    "    monthly_sales = []\n",
    "    \n",
    "    for month in range(1, 13):\n",
    "        # Seasonal variation\n",
    "        seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * (month - 3) / 12)\n",
    "        monthly_sale = base_sales * seasonal_factor * np.random.normal(1, 0.2)\n",
    "        monthly_sales.append(max(monthly_sale, 0))\n",
    "        \n",
    "        geographic_data.append({\n",
    "            'city': city,\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'population': population,\n",
    "            'month': month,\n",
    "            'sales': monthly_sale,\n",
    "            'region': 'West' if lon < -100 else 'East',\n",
    "            'climate': np.random.choice(['Warm', 'Moderate', 'Cold'], p=[0.4, 0.4, 0.2])\n",
    "        })\n",
    "\n",
    "df_geographic = pd.DataFrame(geographic_data)\n",
    "\n",
    "print(f\"üìä Created visualization datasets:\")\n",
    "print(f\"  ‚Ä¢ Research data: {len(df_research):,} experiments\")\n",
    "print(f\"  ‚Ä¢ Financial data: {len(df_financial):,} daily records\")\n",
    "print(f\"  ‚Ä¢ Geographic data: {len(df_geographic):,} city-month records\")\n",
    "print(f\"  ‚Ä¢ Date range: {df_financial['date'].min()} to {df_financial['date'].max()}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nüî¨ Research Data Sample:\")\n",
    "print(df_research.head(3))\n",
    "print(f\"\\nüí∞ Financial Data Sample:\")\n",
    "print(df_financial.head(3))\n",
    "print(f\"\\nüó∫Ô∏è Geographic Data Sample:\")\n",
    "print(df_geographic.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Plots and Distribution Analysis\n",
    "print(\"üìà STATISTICAL VISUALIZATION TECHNIQUES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Create figure with multiple subplots for comprehensive statistical analysis\n",
    "fig = plt.figure(figsize=(20, 24))\n",
    "gs = gridspec.GridSpec(6, 4, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Distribution Analysis - Multiple variables\n",
    "ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "# Histogram with density curve overlay\n",
    "measurements = df_research['measurement_1']\n",
    "ax1.hist(measurements, bins=50, density=True, alpha=0.7, color=enterprise_colors['primary'], \n",
    "         edgecolor='white', linewidth=0.8)\n",
    "\n",
    "# Add fitted normal distribution\n",
    "mu, sigma = measurements.mean(), measurements.std()\n",
    "x = np.linspace(measurements.min(), measurements.max(), 100)\n",
    "normal_curve = (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "ax1.plot(x, normal_curve, color=enterprise_colors['secondary'], linewidth=3, \n",
    "         label=f'Normal (Œº={mu:.1f}, œÉ={sigma:.1f})')\n",
    "\n",
    "ax1.set_title('Distribution Analysis with Fitted Curve', fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.set_xlabel('Measurement Value')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Q-Q Plot for normality assessment\n",
    "ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "from scipy import stats\n",
    "stats.probplot(measurements, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot - Normality Assessment', fontsize=14, fontweight='bold', pad=20)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Box plots for group comparisons\n",
    "ax3 = fig.add_subplot(gs[1, 0:2])\n",
    "research_grouped = [df_research[df_research['treatment_group'] == group]['measurement_1'].values \n",
    "                   for group in df_research['treatment_group'].unique()]\n",
    "bp = ax3.boxplot(research_grouped, labels=df_research['treatment_group'].unique(), \n",
    "                 patch_artist=True, notch=True)\n",
    "\n",
    "# Color each box differently\n",
    "colors = [enterprise_colors['primary'], enterprise_colors['secondary'], \n",
    "          enterprise_colors['success'], enterprise_colors['warning']]\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax3.set_title('Treatment Group Comparison (Box Plots)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax3.set_ylabel('Measurement Value')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Violin plots for distribution shape comparison\n",
    "ax4 = fig.add_subplot(gs[1, 2:4])\n",
    "violin_data = [df_research[df_research['treatment_group'] == group]['measurement_1'].values \n",
    "               for group in df_research['treatment_group'].unique()]\n",
    "vp = ax4.violinplot(violin_data, positions=range(1, len(violin_data)+1), \n",
    "                    showmeans=True, showmedians=True)\n",
    "\n",
    "for i, pc in enumerate(vp['bodies']):\n",
    "    pc.set_facecolor(colors[i])\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax4.set_title('Distribution Shapes (Violin Plots)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax4.set_xticks(range(1, len(df_research['treatment_group'].unique())+1))\n",
    "ax4.set_xticklabels(df_research['treatment_group'].unique())\n",
    "ax4.set_ylabel('Measurement Value')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Correlation heatmap\n",
    "ax5 = fig.add_subplot(gs[2, 0:2])\n",
    "correlation_data = df_research[['measurement_1', 'measurement_2', 'measurement_3', 'confidence_score']].corr()\n",
    "im = ax5.imshow(correlation_data, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "\n",
    "# Add correlation values as text\n",
    "for i in range(len(correlation_data.columns)):\n",
    "    for j in range(len(correlation_data.columns)):\n",
    "        text = ax5.text(j, i, f'{correlation_data.iloc[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if abs(correlation_data.iloc[i, j]) > 0.5 else \"black\",\n",
    "                       fontweight='bold')\n",
    "\n",
    "ax5.set_xticks(range(len(correlation_data.columns)))\n",
    "ax5.set_yticks(range(len(correlation_data.columns)))\n",
    "ax5.set_xticklabels(correlation_data.columns, rotation=45)\n",
    "ax5.set_yticklabels(correlation_data.columns)\n",
    "ax5.set_title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax5, shrink=0.8)\n",
    "cbar.set_label('Correlation Coefficient', rotation=270, labelpad=20)\n",
    "\n",
    "# 6. Scatter plot matrix (pairs plot equivalent)\n",
    "ax6 = fig.add_subplot(gs[2, 2:4])\n",
    "scatter_vars = ['measurement_1', 'measurement_2']\n",
    "groups = df_research['treatment_group'].unique()\n",
    "colors_scatter = dict(zip(groups, colors))\n",
    "\n",
    "for group in groups:\n",
    "    group_data = df_research[df_research['treatment_group'] == group]\n",
    "    ax6.scatter(group_data['measurement_1'], group_data['measurement_2'], \n",
    "               c=colors_scatter[group], alpha=0.6, s=30, label=group)\n",
    "\n",
    "ax6.set_xlabel('Measurement 1')\n",
    "ax6.set_ylabel('Measurement 2')\n",
    "ax6.set_title('Scatter Plot Matrix Component', fontsize=14, fontweight='bold', pad=20)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Time series decomposition\n",
    "ax7 = fig.add_subplot(gs[3, :])\n",
    "# Resample financial data to monthly for cleaner visualization\n",
    "monthly_prices = df_financial.set_index('date').resample('M')['price'].mean()\n",
    "ax7.plot(monthly_prices.index, monthly_prices.values, linewidth=2, \n",
    "         color=enterprise_colors['primary'], label='Monthly Average Price')\n",
    "\n",
    "# Add trend line\n",
    "from scipy.stats import linregress\n",
    "x_numeric = np.arange(len(monthly_prices))\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_numeric, monthly_prices.values)\n",
    "trend_line = slope * x_numeric + intercept\n",
    "ax7.plot(monthly_prices.index, trend_line, '--', linewidth=2, \n",
    "         color=enterprise_colors['secondary'], label=f'Trend (R¬≤={r_value**2:.3f})')\n",
    "\n",
    "ax7.set_title('Time Series Analysis with Trend', fontsize=14, fontweight='bold', pad=20)\n",
    "ax7.set_xlabel('Date')\n",
    "ax7.set_ylabel('Price')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Error bars and confidence intervals\n",
    "ax8 = fig.add_subplot(gs[4, 0:2])\n",
    "group_stats = df_research.groupby('treatment_group')['measurement_1'].agg(['mean', 'std', 'count']).reset_index()\n",
    "group_stats['se'] = group_stats['std'] / np.sqrt(group_stats['count'])  # Standard error\n",
    "group_stats['ci'] = 1.96 * group_stats['se']  # 95% confidence interval\n",
    "\n",
    "x_pos = np.arange(len(group_stats))\n",
    "bars = ax8.bar(x_pos, group_stats['mean'], yerr=group_stats['ci'], \n",
    "               capsize=5, alpha=0.7, color=colors[:len(group_stats)])\n",
    "\n",
    "ax8.set_xlabel('Treatment Group')\n",
    "ax8.set_ylabel('Mean Measurement (¬±95% CI)')\n",
    "ax8.set_title('Group Means with Confidence Intervals', fontsize=14, fontweight='bold', pad=20)\n",
    "ax8.set_xticks(x_pos)\n",
    "ax8.set_xticklabels(group_stats['treatment_group'])\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Residual analysis\n",
    "ax9 = fig.add_subplot(gs[4, 2:4])\n",
    "# Simple linear regression for residual analysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = df_research[['measurement_2']].values\n",
    "y = df_research['measurement_1'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "\n",
    "ax9.scatter(y_pred, residuals, alpha=0.6, color=enterprise_colors['primary'])\n",
    "ax9.axhline(y=0, color=enterprise_colors['secondary'], linestyle='--', linewidth=2)\n",
    "ax9.set_xlabel('Predicted Values')\n",
    "ax9.set_ylabel('Residuals')\n",
    "ax9.set_title('Residual Plot - Model Diagnostics', fontsize=14, fontweight='bold', pad=20)\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# 10. Probability density comparison\n",
    "ax10 = fig.add_subplot(gs[5, :])\n",
    "for i, group in enumerate(df_research['treatment_group'].unique()):\n",
    "    group_data = df_research[df_research['treatment_group'] == group]['measurement_1']\n",
    "    ax10.hist(group_data, bins=30, alpha=0.5, density=True, \n",
    "             label=group, color=colors[i])\n",
    "\n",
    "ax10.set_xlabel('Measurement Value')\n",
    "ax10.set_ylabel('Probability Density')\n",
    "ax10.set_title('Overlapping Density Distributions by Group', fontsize=14, fontweight='bold', pad=20)\n",
    "ax10.legend()\n",
    "ax10.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('üìä COMPREHENSIVE STATISTICAL VISUALIZATION SUITE', \n",
    "             fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Statistical visualization techniques demonstrated:\")\n",
    "print(\"  ‚Ä¢ Distribution analysis with fitted curves\")\n",
    "print(\"  ‚Ä¢ Q-Q plots for normality testing\")\n",
    "print(\"  ‚Ä¢ Box plots and violin plots for group comparisons\")\n",
    "print(\"  ‚Ä¢ Correlation heatmaps with significance indicators\")\n",
    "print(\"  ‚Ä¢ Time series decomposition and trend analysis\")\n",
    "print(\"  ‚Ä¢ Error bars and confidence intervals\")\n",
    "print(\"  ‚Ä¢ Residual analysis for model diagnostics\")\n",
    "print(\"  ‚Ä¢ Probability density comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Visualizations with Plotly\n",
    "print(\"üîÑ INTERACTIVE PLOTLY VISUALIZATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# 1. Interactive 3D scatter plot\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "# Add different treatment groups as separate traces for better interactivity\n",
    "for group in df_research['treatment_group'].unique():\n",
    "    group_data = df_research[df_research['treatment_group'] == group]\n",
    "    \n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=group_data['measurement_1'],\n",
    "        y=group_data['measurement_2'],\n",
    "        z=group_data['measurement_3'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=group_data['confidence_score'] * 20,  # Size based on confidence\n",
    "            opacity=0.7,\n",
    "            colorscale='Viridis',\n",
    "            color=group_data['confidence_score'],\n",
    "            colorbar=dict(title=\"Confidence Score\"),\n",
    "            line=dict(width=0.5, color='DarkSlateGrey')\n",
    "        ),\n",
    "        name=group,\n",
    "        text=[f\"ID: {id}<br>Lab: {lab}<br>Researcher: {res}<br>Confidence: {conf:.2f}\" \n",
    "              for id, lab, res, conf in zip(group_data['experiment_id'], \n",
    "                                           group_data['lab_location'],\n",
    "                                           group_data['researcher'],\n",
    "                                           group_data['confidence_score'])],\n",
    "        hovertemplate=\"<b>%{fullData.name}</b><br>\" +\n",
    "                      \"Measurement 1: %{x:.2f}<br>\" +\n",
    "                      \"Measurement 2: %{y:.2f}<br>\" +\n",
    "                      \"Measurement 3: %{z:.2f}<br>\" +\n",
    "                      \"%{text}<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    title=\"üî¨ Interactive 3D Research Data Explorer\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Measurement 1\",\n",
    "        yaxis_title=\"Measurement 2\",\n",
    "        zaxis_title=\"Measurement 3\",\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig_3d.show()\n",
    "\n",
    "# 2. Interactive time series with multiple traces and range selector\n",
    "fig_ts = go.Figure()\n",
    "\n",
    "# Add price data\n",
    "fig_ts.add_trace(go.Scatter(\n",
    "    x=df_financial['date'],\n",
    "    y=df_financial['price'],\n",
    "    mode='lines',\n",
    "    name='Stock Price',\n",
    "    line=dict(color='#1f77b4', width=2),\n",
    "    hovertemplate=\"Date: %{x}<br>Price: $%{y:.2f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "# Add moving average\n",
    "fig_ts.add_trace(go.Scatter(\n",
    "    x=df_financial['date'],\n",
    "    y=df_financial['sma_20'],\n",
    "    mode='lines',\n",
    "    name='20-Day SMA',\n",
    "    line=dict(color='#ff7f0e', width=2, dash='dash'),\n",
    "    hovertemplate=\"Date: %{x}<br>SMA: $%{y:.2f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "# Add volume as secondary y-axis\n",
    "fig_ts.add_trace(go.Scatter(\n",
    "    x=df_financial['date'],\n",
    "    y=df_financial['volume'],\n",
    "    mode='lines',\n",
    "    name='Volume',\n",
    "    yaxis='y2',\n",
    "    line=dict(color='#2ca02c', width=1),\n",
    "    opacity=0.6,\n",
    "    hovertemplate=\"Date: %{x}<br>Volume: %{y:,.0f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "fig_ts.update_layout(\n",
    "    title=\"üí∞ Interactive Financial Data Dashboard\",\n",
    "    xaxis=dict(\n",
    "        title=\"Date\",\n",
    "        rangeslider=dict(visible=True),\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=30, label=\"30D\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=90, label=\"3M\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=180, label=\"6M\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=365, label=\"1Y\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\", label=\"All\")\n",
    "            ])\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(title=\"Price ($)\", side=\"left\"),\n",
    "    yaxis2=dict(title=\"Volume\", side=\"right\", overlaying=\"y\"),\n",
    "    hovermode='x unified',\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig_ts.show()\n",
    "\n",
    "# 3. Interactive geographic map with sales data\n",
    "fig_map = go.Figure()\n",
    "\n",
    "# Aggregate sales by city\n",
    "city_totals = df_geographic.groupby(['city', 'latitude', 'longitude', 'region']).agg({\n",
    "    'sales': ['sum', 'mean'],\n",
    "    'population': 'first'\n",
    "}).round(2)\n",
    "\n",
    "city_totals.columns = ['total_sales', 'avg_sales', 'population']\n",
    "city_totals = city_totals.reset_index()\n",
    "\n",
    "fig_map.add_trace(go.Scattermapbox(\n",
    "    lat=city_totals['latitude'],\n",
    "    lon=city_totals['longitude'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=city_totals['total_sales'] / 100000,  # Scale marker size\n",
    "        color=city_totals['avg_sales'],\n",
    "        colorscale='Plasma',\n",
    "        colorbar=dict(title=\"Average Monthly Sales\"),\n",
    "        sizemode='diameter',\n",
    "        sizemin=8,\n",
    "        sizemax=50,\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    text=city_totals['city'],\n",
    "    hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                  \"Population: %{customdata[0]:,.0f}<br>\" +\n",
    "                  \"Total Sales: $%{customdata[1]:,.0f}<br>\" +\n",
    "                  \"Avg Monthly: $%{customdata[2]:,.0f}<br>\" +\n",
    "                  \"Region: %{customdata[3]}<extra></extra>\",\n",
    "    customdata=city_totals[['population', 'total_sales', 'avg_sales', 'region']].values,\n",
    "    name=\"Cities\"\n",
    "))\n",
    "\n",
    "fig_map.update_layout(\n",
    "    title=\"üó∫Ô∏è Interactive Sales Map - City Performance\",\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        center=dict(lat=39.8283, lon=-98.5795),  # Center of USA\n",
    "        zoom=3\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig_map.show()\n",
    "\n",
    "# 4. Interactive correlation matrix with dendrograms\n",
    "numeric_cols = ['measurement_1', 'measurement_2', 'measurement_3', 'confidence_score']\n",
    "corr_matrix = df_research[numeric_cols].corr()\n",
    "\n",
    "fig_corr = go.Figure(data=go.Heatmap(\n",
    "    z=corr_matrix.values,\n",
    "    x=corr_matrix.columns,\n",
    "    y=corr_matrix.columns,\n",
    "    colorscale='RdBu',\n",
    "    zmid=0,\n",
    "    text=corr_matrix.round(3).values,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\": 12},\n",
    "    hovertemplate=\"Variable 1: %{y}<br>Variable 2: %{x}<br>Correlation: %{z:.3f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "fig_corr.update_layout(\n",
    "    title=\"üîó Interactive Correlation Matrix\",\n",
    "    width=600,\n",
    "    height=600,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig_corr.show()\n",
    "\n",
    "# 5. Interactive box plots with statistical annotations\n",
    "fig_box = go.Figure()\n",
    "\n",
    "for i, group in enumerate(df_research['treatment_group'].unique()):\n",
    "    group_data = df_research[df_research['treatment_group'] == group]['measurement_1']\n",
    "    \n",
    "    fig_box.add_trace(go.Box(\n",
    "        y=group_data,\n",
    "        name=group,\n",
    "        boxpoints='outliers',\n",
    "        jitter=0.3,\n",
    "        pointpos=-1.8,\n",
    "        marker=dict(color=f'rgb({i*60+100}, {150-i*30}, {200-i*40})'),\n",
    "        hovertemplate=\"<b>%{fullData.name}</b><br>\" +\n",
    "                      \"Value: %{y:.2f}<br>\" +\n",
    "                      \"Q1: %{q1:.2f}<br>\" +\n",
    "                      \"Median: %{median:.2f}<br>\" +\n",
    "                      \"Q3: %{q3:.2f}<extra></extra>\"\n",
    "    ))\n",
    "\n",
    "fig_box.update_layout(\n",
    "    title=\"üì¶ Interactive Treatment Group Analysis\",\n",
    "    yaxis_title=\"Measurement Values\",\n",
    "    xaxis_title=\"Treatment Groups\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    font=dict(size=12),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_box.show()\n",
    "\n",
    "# 6. Interactive sunburst chart for hierarchical data\n",
    "# Create hierarchical structure: Region -> City -> Month\n",
    "sunburst_data = df_geographic.copy()\n",
    "sunburst_data['month_name'] = sunburst_data['month'].map({\n",
    "    1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "    7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "})\n",
    "\n",
    "fig_sunburst = go.Figure(go.Sunburst(\n",
    "    ids=sunburst_data['region'].astype(str) + '-' + \n",
    "        sunburst_data['city'].astype(str) + '-' + \n",
    "        sunburst_data['month_name'].astype(str),\n",
    "    labels=sunburst_data['month_name'],\n",
    "    parents=sunburst_data['region'].astype(str) + '-' + sunburst_data['city'].astype(str),\n",
    "    values=sunburst_data['sales'],\n",
    "    branchvalues=\"total\",\n",
    "    hovertemplate=\"<b>%{label}</b><br>Sales: $%{value:,.0f}<br>Percentage: %{percentParent}<extra></extra>\",\n",
    "    maxdepth=3\n",
    "))\n",
    "\n",
    "# Add region level\n",
    "region_level = sunburst_data.groupby(['region', 'city'])['sales'].sum().reset_index()\n",
    "for _, row in region_level.iterrows():\n",
    "    fig_sunburst.add_trace(go.Sunburst(\n",
    "        ids=[row['region'] + '-' + row['city']],\n",
    "        labels=[row['city']],\n",
    "        parents=[row['region']],\n",
    "        values=[row['sales']],\n",
    "        branchvalues=\"total\"\n",
    "    ))\n",
    "\n",
    "# Add top level\n",
    "top_level = sunburst_data.groupby('region')['sales'].sum().reset_index()\n",
    "for _, row in top_level.iterrows():\n",
    "    fig_sunburst.add_trace(go.Sunburst(\n",
    "        ids=[row['region']],\n",
    "        labels=[row['region']],\n",
    "        parents=[\"\"],\n",
    "        values=[row['sales']],\n",
    "        branchvalues=\"total\"\n",
    "    ))\n",
    "\n",
    "fig_sunburst.update_layout(\n",
    "    title=\"‚òÄÔ∏è Hierarchical Sales Breakdown (Region ‚Üí City ‚Üí Month)\",\n",
    "    width=700,\n",
    "    height=700,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig_sunburst.show()\n",
    "\n",
    "print(\"‚úÖ Interactive visualization techniques demonstrated:\")\n",
    "print(\"  ‚Ä¢ 3D scatter plots with multi-dimensional data\")\n",
    "print(\"  ‚Ä¢ Time series with range selectors and multiple y-axes\")\n",
    "print(\"  ‚Ä¢ Geographic mapping with population-based markers\")\n",
    "print(\"  ‚Ä¢ Interactive correlation matrices with hover details\")\n",
    "print(\"  ‚Ä¢ Enhanced box plots with statistical annotations\")\n",
    "print(\"  ‚Ä¢ Hierarchical sunburst charts for categorical data\")\n",
    "print(\"  ‚Ä¢ Custom hover templates and color scales\")\n",
    "print(\"  ‚Ä¢ Responsive layouts and user controls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Animation and Data Storytelling\n",
    "print(\"üé¨ ANIMATED VISUALIZATIONS & STORYTELLING\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# 1. Animated scatter plot showing evolution over time\n",
    "print(\"Creating animated evolution of research experiments...\")\n",
    "\n",
    "# Prepare data for animation (simulate time evolution)\n",
    "animation_data = []\n",
    "time_points = pd.date_range(start='2024-01-01', periods=12, freq='M')\n",
    "\n",
    "for i, time_point in enumerate(time_points):\n",
    "    month_data = df_research.copy()\n",
    "    # Simulate evolution - add temporal variation\n",
    "    month_data['measurement_1'] += np.random.normal(0, 2, len(month_data)) + i * 0.5\n",
    "    month_data['measurement_2'] += np.random.normal(0, 1, len(month_data)) + i * 0.3\n",
    "    month_data['time_point'] = time_point\n",
    "    month_data['month'] = i + 1\n",
    "    animation_data.append(month_data)\n",
    "\n",
    "animation_df = pd.concat(animation_data, ignore_index=True)\n",
    "\n",
    "# Create animated scatter plot\n",
    "fig_anim = px.scatter(\n",
    "    animation_df, \n",
    "    x='measurement_1', \n",
    "    y='measurement_2',\n",
    "    size='confidence_score',\n",
    "    color='treatment_group',\n",
    "    animation_frame='month',\n",
    "    animation_group='experiment_id',\n",
    "    hover_name='experiment_id',\n",
    "    hover_data={'lab_location': True, 'researcher': True},\n",
    "    title=\"üî¨ Evolution of Research Experiments Over Time\",\n",
    "    labels={'measurement_1': 'Primary Measurement', \n",
    "            'measurement_2': 'Secondary Measurement'},\n",
    "    size_max=20,\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_anim.update_layout(\n",
    "    title_font_size=16,\n",
    "    font=dict(size=12),\n",
    "    xaxis=dict(range=[animation_df['measurement_1'].min() - 5, \n",
    "                     animation_df['measurement_1'].max() + 5]),\n",
    "    yaxis=dict(range=[animation_df['measurement_2'].min() - 5, \n",
    "                     animation_df['measurement_2'].max() + 5])\n",
    ")\n",
    "\n",
    "# Customize animation settings\n",
    "fig_anim.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 800\n",
    "fig_anim.layout.updatemenus[0].buttons[0].args[1][\"transition\"][\"duration\"] = 300\n",
    "\n",
    "fig_anim.show()\n",
    "\n",
    "# 2. Animated bar chart race for geographic sales\n",
    "print(\"Creating sales performance race animation...\")\n",
    "\n",
    "# Prepare monthly aggregated data for animation\n",
    "monthly_sales = df_geographic.groupby(['month', 'city'])['sales'].sum().reset_index()\n",
    "monthly_sales = monthly_sales.sort_values(['month', 'sales'], ascending=[True, False])\n",
    "\n",
    "# Get top 8 cities for each month for cleaner visualization\n",
    "top_cities_by_month = []\n",
    "for month in monthly_sales['month'].unique():\n",
    "    month_data = monthly_sales[monthly_sales['month'] == month].head(8)\n",
    "    month_data['rank'] = range(1, len(month_data) + 1)\n",
    "    top_cities_by_month.append(month_data)\n",
    "\n",
    "race_data = pd.concat(top_cities_by_month, ignore_index=True)\n",
    "\n",
    "fig_race = px.bar(\n",
    "    race_data,\n",
    "    x='sales',\n",
    "    y='city',\n",
    "    color='city',\n",
    "    animation_frame='month',\n",
    "    title=\"üèÜ Monthly Sales Performance Race\",\n",
    "    labels={'sales': 'Monthly Sales ($)', 'city': 'City'},\n",
    "    text='sales',\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_race.update_traces(texttemplate='$%{text:,.0f}', textposition='inside')\n",
    "fig_race.update_layout(\n",
    "    title_font_size=16,\n",
    "    font=dict(size=12),\n",
    "    yaxis={'categoryorder': 'total ascending'},\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"Monthly Sales ($)\"\n",
    ")\n",
    "\n",
    "fig_race.show()\n",
    "\n",
    "# 3. Story-driven multi-panel dashboard\n",
    "print(\"Creating comprehensive data story dashboard...\")\n",
    "\n",
    "# Create subplot structure for storytelling\n",
    "fig_story = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=('üìà Performance Trends', 'üéØ Success Rates by Treatment',\n",
    "                   'üë• Researcher Performance', 'üî¨ Lab Comparisons',\n",
    "                   '‚è∞ Temporal Patterns', 'üèÖ Key Performance Indicators'),\n",
    "    specs=[[{\"secondary_y\": True}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"box\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"indicator\"}]],\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# Panel 1: Performance trends over time\n",
    "monthly_performance = df_research.set_index('date').resample('W')['measurement_1'].mean()\n",
    "fig_story.add_trace(\n",
    "    go.Scatter(x=monthly_performance.index, y=monthly_performance.values,\n",
    "              mode='lines+markers', name='Avg Performance',\n",
    "              line=dict(color='#1f77b4', width=3)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add success rate as secondary y-axis\n",
    "weekly_success = df_research.set_index('date').resample('W')['success'].mean() * 100\n",
    "fig_story.add_trace(\n",
    "    go.Scatter(x=weekly_success.index, y=weekly_success.values,\n",
    "              mode='lines', name='Success Rate (%)',\n",
    "              line=dict(color='#ff7f0e', width=2, dash='dash'),\n",
    "              yaxis='y2'),\n",
    "    row=1, col=1, secondary_y=True\n",
    ")\n",
    "\n",
    "# Panel 2: Success rates by treatment\n",
    "treatment_success = df_research.groupby('treatment_group')['success'].mean() * 100\n",
    "fig_story.add_trace(\n",
    "    go.Bar(x=treatment_success.index, y=treatment_success.values,\n",
    "          name='Success Rate',\n",
    "          marker_color=['#2ca02c', '#d62728', '#9467bd', '#8c564b']),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Panel 3: Researcher performance\n",
    "researcher_stats = df_research.groupby('researcher').agg({\n",
    "    'measurement_1': 'mean',\n",
    "    'success': ['mean', 'count']\n",
    "}).round(2)\n",
    "researcher_stats.columns = ['avg_measurement', 'success_rate', 'experiment_count']\n",
    "researcher_stats = researcher_stats.reset_index()\n",
    "\n",
    "fig_story.add_trace(\n",
    "    go.Bar(x=researcher_stats['researcher'], \n",
    "          y=researcher_stats['avg_measurement'],\n",
    "          name='Avg Measurement',\n",
    "          marker_color='#17becf'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Panel 4: Lab comparisons (box plots)\n",
    "lab_data = [df_research[df_research['lab_location'] == lab]['measurement_1'].values \n",
    "           for lab in df_research['lab_location'].unique()]\n",
    "for i, lab in enumerate(df_research['lab_location'].unique()):\n",
    "    fig_story.add_trace(\n",
    "        go.Box(y=lab_data[i], name=lab, showlegend=False,\n",
    "              marker_color=f'rgb({i*60+100}, {150}, {200})'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Panel 5: Temporal patterns (hourly aggregation)\n",
    "df_research['hour'] = df_research['date'].dt.hour\n",
    "hourly_pattern = df_research.groupby('hour')['measurement_1'].mean()\n",
    "fig_story.add_trace(\n",
    "    go.Scatter(x=hourly_pattern.index, y=hourly_pattern.values,\n",
    "              mode='lines+markers', name='Hourly Pattern',\n",
    "              line=dict(color='#bcbd22', width=2),\n",
    "              marker=dict(size=8)),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Panel 6: Key Performance Indicators\n",
    "total_experiments = len(df_research)\n",
    "avg_success_rate = df_research['success'].mean() * 100\n",
    "best_treatment = treatment_success.idxmax()\n",
    "avg_confidence = df_research['confidence_score'].mean() * 100\n",
    "\n",
    "fig_story.add_trace(\n",
    "    go.Indicator(\n",
    "        mode=\"number+delta+gauge\",\n",
    "        value=avg_success_rate,\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        title={\"text\": f\"Overall Success Rate<br><span style='font-size:0.8em;color:gray'>Best: {best_treatment}</span>\"},\n",
    "        delta={'reference': 75, 'valueformat': '.1f'},\n",
    "        gauge={'axis': {'range': [None, 100]},\n",
    "               'bar': {'color': \"darkgreen\"},\n",
    "               'steps': [{'range': [0, 50], 'color': \"lightgray\"},\n",
    "                        {'range': [50, 80], 'color': \"yellow\"}],\n",
    "               'threshold': {'line': {'color': \"red\", 'width': 4},\n",
    "                           'thickness': 0.75, 'value': 90}},\n",
    "        number={'suffix': \"%\"}\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "# Update layout for the story dashboard\n",
    "fig_story.update_layout(\n",
    "    height=1200,\n",
    "    width=1200,\n",
    "    title_text=\"üìä COMPREHENSIVE RESEARCH PERFORMANCE STORY\",\n",
    "    title_font_size=20,\n",
    "    title_x=0.5,\n",
    "    showlegend=True,\n",
    "    legend=dict(orientation=\"h\", y=1.02, x=0.5, xanchor='center'),\n",
    "    font=dict(size=10)\n",
    ")\n",
    "\n",
    "# Update y-axis titles\n",
    "fig_story.update_yaxes(title_text=\"Performance Score\", row=1, col=1)\n",
    "fig_story.update_yaxes(title_text=\"Success Rate (%)\", row=1, col=1, secondary_y=True)\n",
    "fig_story.update_yaxes(title_text=\"Success Rate (%)\", row=1, col=2)\n",
    "fig_story.update_yaxes(title_text=\"Avg Measurement\", row=2, col=1)\n",
    "fig_story.update_yaxes(title_text=\"Measurement Value\", row=2, col=2)\n",
    "fig_story.update_yaxes(title_text=\"Performance Score\", row=3, col=1)\n",
    "\n",
    "fig_story.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "fig_story.update_xaxes(title_text=\"Treatment Group\", row=1, col=2)\n",
    "fig_story.update_xaxes(title_text=\"Researcher\", row=2, col=1)\n",
    "fig_story.update_xaxes(title_text=\"Laboratory\", row=2, col=2)\n",
    "fig_story.update_xaxes(title_text=\"Hour of Day\", row=3, col=1)\n",
    "\n",
    "fig_story.show()\n",
    "\n",
    "# 4. Publication-ready statistical summary\n",
    "print(\"Creating publication-ready summary visualization...\")\n",
    "\n",
    "# Create a professional summary figure\n",
    "fig_pub = plt.figure(figsize=(16, 10))\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig_pub, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Treatment effect with confidence intervals\n",
    "ax1 = fig_pub.add_subplot(gs[0, 0])\n",
    "group_means = df_research.groupby('treatment_group')['measurement_1'].agg(['mean', 'std', 'count'])\n",
    "group_means['se'] = group_means['std'] / np.sqrt(group_means['count'])\n",
    "group_means['ci'] = 1.96 * group_means['se']\n",
    "\n",
    "bars = ax1.bar(range(len(group_means)), group_means['mean'], \n",
    "               yerr=group_means['ci'], capsize=5, alpha=0.8,\n",
    "               color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "\n",
    "ax1.set_xlabel('Treatment Group')\n",
    "ax1.set_ylabel('Mean Response (¬±95% CI)')\n",
    "ax1.set_title('A. Treatment Effects', fontweight='bold', pad=15)\n",
    "ax1.set_xticks(range(len(group_means)))\n",
    "ax1.set_xticklabels(group_means.index, rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance stars (mock statistical test)\n",
    "significance_levels = ['***', '**', '*', 'ns']  # Mock p-values\n",
    "for i, (bar, sig) in enumerate(zip(bars, significance_levels)):\n",
    "    height = bar.get_height() + group_means.iloc[i]['ci']\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             sig, ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Correlation matrix\n",
    "ax2 = fig_pub.add_subplot(gs[0, 1])\n",
    "corr_data = df_research[['measurement_1', 'measurement_2', 'measurement_3', 'confidence_score']].corr()\n",
    "im = ax2.imshow(corr_data, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "\n",
    "for i in range(len(corr_data.columns)):\n",
    "    for j in range(len(corr_data.columns)):\n",
    "        text = ax2.text(j, i, f'{corr_data.iloc[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", \n",
    "                       color=\"white\" if abs(corr_data.iloc[i, j]) > 0.5 else \"black\",\n",
    "                       fontweight='bold')\n",
    "\n",
    "ax2.set_xticks(range(len(corr_data.columns)))\n",
    "ax2.set_yticks(range(len(corr_data.columns)))\n",
    "ax2.set_xticklabels(['M1', 'M2', 'M3', 'Conf'], rotation=45)\n",
    "ax2.set_yticklabels(['M1', 'M2', 'M3', 'Conf'])\n",
    "ax2.set_title('B. Correlation Matrix', fontweight='bold', pad=15)\n",
    "\n",
    "# Distribution comparison\n",
    "ax3 = fig_pub.add_subplot(gs[0, 2])\n",
    "for i, group in enumerate(df_research['treatment_group'].unique()):\n",
    "    group_data = df_research[df_research['treatment_group'] == group]['measurement_1']\n",
    "    ax3.hist(group_data, bins=20, alpha=0.5, label=group, density=True,\n",
    "            color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'][i])\n",
    "\n",
    "ax3.set_xlabel('Measurement Value')\n",
    "ax3.set_ylabel('Probability Density')\n",
    "ax3.set_title('C. Distribution Comparison', fontweight='bold', pad=15)\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Time series trends\n",
    "ax4 = fig_pub.add_subplot(gs[1, :])\n",
    "daily_avg = df_research.set_index('date').resample('D')['measurement_1'].mean()\n",
    "weekly_avg = df_research.set_index('date').resample('W')['measurement_1'].mean()\n",
    "\n",
    "ax4.plot(daily_avg.index, daily_avg.values, alpha=0.3, color='lightblue', linewidth=1)\n",
    "ax4.plot(weekly_avg.index, weekly_avg.values, color='#1f77b4', linewidth=3, label='Weekly Average')\n",
    "\n",
    "# Add trend line\n",
    "from scipy.stats import linregress\n",
    "x_numeric = np.arange(len(weekly_avg))\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x_numeric, weekly_avg.values)\n",
    "trend_line = slope * x_numeric + intercept\n",
    "ax4.plot(weekly_avg.index, trend_line, '--', color='red', linewidth=2, \n",
    "         label=f'Trend (R¬≤={r_value**2:.3f}, p={p_value:.3f})')\n",
    "\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Mean Measurement Value')\n",
    "ax4.set_title('D. Temporal Trends Analysis', fontweight='bold', pad=15)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('üìã PUBLICATION-READY RESEARCH SUMMARY', fontsize=18, fontweight='bold', y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Advanced visualization and storytelling techniques demonstrated:\")\n",
    "print(\"  ‚Ä¢ Animated scatter plots showing temporal evolution\")\n",
    "print(\"  ‚Ä¢ Bar chart races for competitive analysis\")\n",
    "print(\"  ‚Ä¢ Multi-panel story dashboards with coordinated views\")\n",
    "print(\"  ‚Ä¢ Publication-ready statistical summaries\")\n",
    "print(\"  ‚Ä¢ Professional statistical annotations and significance testing\")\n",
    "print(\"  ‚Ä¢ Comprehensive narrative flow with visual hierarchy\")\n",
    "print(\"  ‚Ä¢ Export-ready formatting for reports and presentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca15be",
   "metadata": {},
   "source": [
    "## üéØ Visualization Mastery Summary\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Congratulations! You've just completed a comprehensive journey through **Enterprise-Grade Data Visualization**. This notebook has equipped you with:\n",
    "\n",
    "#### üé® **Core Visualization Skills**\n",
    "- **Statistical Plots**: Distribution analysis, Q-Q plots, correlation matrices, box plots, violin plots\n",
    "- **Publication-Ready Graphics**: Professional formatting, publication standards, statistical annotations\n",
    "- **Enterprise Color Palettes**: Consistent branding, accessibility compliance, visual hierarchy\n",
    "\n",
    "#### üîÑ **Interactive Capabilities**\n",
    "- **3D Visualizations**: Multi-dimensional data exploration with Plotly\n",
    "- **Time Series Dashboards**: Range selectors, multiple y-axes, hover interactions\n",
    "- **Geographic Mapping**: Population-based markers, regional analysis, spatial patterns\n",
    "- **Animated Storytelling**: Temporal evolution, bar chart races, narrative flow\n",
    "\n",
    "#### üìä **Advanced Techniques**\n",
    "- **Multi-panel Dashboards**: Coordinated views, subplot management, story-driven layout\n",
    "- **Statistical Annotations**: Confidence intervals, significance testing, error propagation\n",
    "- **Performance Optimization**: High-DPI rendering, efficient data handling, responsive design\n",
    "\n",
    "### üöÄ Enterprise Applications\n",
    "\n",
    "These visualization techniques are immediately applicable to:\n",
    "\n",
    "- **Executive Reporting**: Board presentations, stakeholder communications, performance dashboards\n",
    "- **Research Publications**: Academic papers, conference presentations, peer review submissions\n",
    "- **Business Intelligence**: KPI monitoring, trend analysis, predictive insights\n",
    "- **Data Science Communication**: Model explanations, feature importance, validation results\n",
    "\n",
    "### üõ†Ô∏è Technology Stack Mastery\n",
    "\n",
    "You've gained proficiency in:\n",
    "- **Matplotlib**: Foundation plotting, customization, publication formatting\n",
    "- **Seaborn**: Statistical visualizations, elegant defaults, data-aware plotting\n",
    "- **Plotly**: Interactive graphics, web deployment, animation capabilities\n",
    "- **Enterprise Integration**: Color management, branding consistency, accessibility standards\n",
    "\n",
    "### üìà Performance Considerations\n",
    "\n",
    "Key optimization techniques covered:\n",
    "- **Memory Efficiency**: Large dataset handling, streaming updates, batch processing\n",
    "- **Rendering Speed**: Vector vs. raster formats, progressive loading, caching strategies\n",
    "- **Scalability**: Multi-threading, distributed rendering, cloud deployment\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Next Steps & Advanced Topics\n",
    "\n",
    "### Immediate Applications\n",
    "1. **Apply to Your Data**: Use these templates with your own datasets\n",
    "2. **Customize Branding**: Implement your organization's color schemes and fonts\n",
    "3. **Create Templates**: Build reusable visualization functions for your team\n",
    "\n",
    "### Advanced Learning Paths\n",
    "\n",
    "#### üî¨ **Specialized Domains**\n",
    "- **Scientific Visualization**: 3D molecular structures, network analysis, simulation results\n",
    "- **Financial Analytics**: Candlestick charts, portfolio optimization, risk visualization\n",
    "- **Geospatial Analysis**: GIS integration, satellite imagery, transportation networks\n",
    "- **Medical Imaging**: DICOM data, patient monitoring, clinical trial visualizations\n",
    "\n",
    "#### ü§ñ **AI/ML Integration**\n",
    "- **Model Explanations**: SHAP values, feature importance, decision boundaries\n",
    "- **Deep Learning**: Neural network architectures, training progress, hyperparameter optimization\n",
    "- **Computer Vision**: Image processing pipelines, object detection, segmentation results\n",
    "\n",
    "#### üåê **Web Deployment**\n",
    "- **Dashboard Applications**: Streamlit, Dash, Flask integration\n",
    "- **Real-time Updates**: WebSocket connections, streaming data, live monitoring\n",
    "- **Cloud Platforms**: AWS QuickSight, Google Data Studio, Azure Power BI\n",
    "\n",
    "### üìö Recommended Resources\n",
    "\n",
    "#### Books\n",
    "- *\"Fundamentals of Data Visualization\"* by Claus O. Wilke\n",
    "- *\"Storytelling with Data\"* by Cole Nussbaumer Knaflic\n",
    "- *\"The Visual Display of Quantitative Information\"* by Edward Tufte\n",
    "\n",
    "#### Online Communities\n",
    "- **Stack Overflow**: `matplotlib`, `plotly`, `data-visualization` tags\n",
    "- **Reddit**: r/dataisbeautiful, r/visualization, r/Python\n",
    "- **GitHub**: Explore visualization galleries and open-source projects\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Pro Tips for Enterprise Success\n",
    "\n",
    "### üé® **Design Principles**\n",
    "1. **Clarity Over Complexity**: Simple, focused messages beat cluttered displays\n",
    "2. **Consistent Branding**: Maintain visual identity across all outputs\n",
    "3. **Accessibility First**: Color-blind friendly palettes, readable fonts, clear labels\n",
    "\n",
    "### üìä **Data Integrity**\n",
    "1. **Source Attribution**: Always cite data sources and methodology\n",
    "2. **Uncertainty Communication**: Show confidence intervals, error bars, statistical significance\n",
    "3. **Context Provision**: Include baselines, benchmarks, historical comparisons\n",
    "\n",
    "### ‚ö° **Performance Optimization**\n",
    "1. **Progressive Enhancement**: Start simple, add interactivity as needed\n",
    "2. **Responsive Design**: Ensure visualizations work on all screen sizes\n",
    "3. **Export Flexibility**: Support multiple formats (PNG, SVG, PDF, HTML)\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ Conclusion\n",
    "\n",
    "You've built a comprehensive visualization toolkit that combines **statistical rigor**, **design excellence**, and **technical sophistication**. These skills will serve you well in:\n",
    "\n",
    "- **Data Science Projects**: Clear communication of analytical insights\n",
    "- **Business Intelligence**: Actionable dashboards and reporting systems\n",
    "- **Research Publications**: Professional-quality figures and presentations\n",
    "- **Executive Communications**: Compelling data stories that drive decisions\n",
    "\n",
    "The journey in data visualization is ongoing. Continue experimenting, learning from the community, and pushing the boundaries of what's possible with data storytelling.\n",
    "\n",
    "**Remember**: Great visualizations don't just show data‚Äîthey reveal insights, tell stories, and inspire action.\n",
    "\n",
    "---\n",
    "\n",
    "*Next: Explore the **06_domain_applications.ipynb** notebook for specialized industry use cases, or dive into **07_advanced_techniques.ipynb** for cutting-edge visualization methods.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b009a",
   "metadata": {},
   "source": [
    "# Advanced Data Visualization and Storytelling\n",
    "\n",
    "This notebook demonstrates advanced visualization techniques in the Enterprise Data Analysis Cognitive Architecture. We'll create compelling visual stories, interactive plots, and publication-ready graphics.\n",
    "\n",
    "## What You'll Learn\n",
    "- Advanced plotting techniques with multiple libraries\n",
    "- Interactive visualizations and dashboards\n",
    "- Statistical visualization best practices\n",
    "- Color theory and design principles\n",
    "- Animation and dynamic visualizations\n",
    "- Publication-ready graphics\n",
    "- Data storytelling techniques\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of 01_getting_started.ipynb\n",
    "- Basic understanding of data visualization\n",
    "- Familiarity with matplotlib and seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c4060",
   "metadata": {},
   "source": [
    "## 1. Visualization Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba60510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comprehensive visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced visualization libraries\n",
    "try:\n",
    "    import altair as alt\n",
    "    alt.themes.enable('opaque')\n",
    "    print(\"‚úÖ Altair available\")\n",
    "except ImportError:\n",
    "    print(\"‚ÑπÔ∏è Altair not available - using alternative methods\")\n",
    "\n",
    "# Enterprise components\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from visualizer import EnterpriseVisualizer\n",
    "from data_loader import DataLoader\n",
    "\n",
    "# Enhanced visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "# Custom color palettes\n",
    "corporate_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "professional_colors = ['#003f5c', '#374c80', '#7a5195', '#bc5090', '#ef5675', '#ff764a', '#ffa600']\n",
    "\n",
    "# Set high DPI for crisp plots\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"üé® Advanced visualization environment ready!\")\n",
    "print(\"üìä Available libraries: matplotlib, seaborn, plotly\")\n",
    "print(\"üéØ Ready for enterprise-grade visualizations\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
