# Enterprise Data Analysis Cognitive Architecture

> **âš ï¸ IMPORTANT: Python 3.11+ Required**
> 
> This project requires **Python 3.11 or higher** for compatibility with all data analysis packages and enterprise features. Python 3.10 and below are not supported due to dependency requirements.

[![Data Analysis](https://img.shields.io/badge/Data_Analysis-Enterprise_Enhanced-green?style=for-the-badge&logo=chartline&logoColor=white)](#) [![Meta Cognitive](https://img.shields.io/badge/Meta-Cognitive-red?style=for-the-badge&logo=psychology)](#) [![Dual Context](https://img.shields.io/badge/Dual_Context-Framework_Integrated-orange?style=for-the-badge&logo=microsoft&logoColor=white)](#) [![Enterprise Framework](https://img.shields.io/badge/9_Point-Framework-gold?style=for-the-badge&logo=shield)](#) [![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python&logoColor=white)](#)

![Data Analysis Cognitive Architecture](MINION-DATA-ANALYSIS.png)

## ğŸ¯ Project Overview

This project implements the **Project Catalyst Enterprise Data Analysis Cognitive Architecture** - an advanced AI-powered system for data analysis excellence and professional statistical analysis. The cognitive architecture combines human memory models with enterprise-grade methodologies to provide intelligent assistance for professional data analysis applications and organizational excellence.

## ğŸ§  Cognitive Architecture Features

### Meta-Cognitive Capabilities
- **Adaptive Learning**: Self-improving system that learns from your data analysis patterns and statistical preferences
- **Memory Management**: Intelligent consolidation of statistical knowledge, methodologies, and best practices
- **Context Awareness**: Dual-context support for Microsoft internal and universal organizational environments
- **Performance Monitoring**: Self-assessment and continuous improvement protocols for data analysis excellence

### Enterprise Integration
- **9-Point Framework**: Security, Testing, Automation, Risk, Performance, Quality, Documentation, Analytics, Compliance
- **SPSS Integration**: Seamless .sav file processing with metadata preservation
- **Statistical Excellence**: Research-grade methodologies with empirical integrity and quality protocols

## ğŸš€ Getting Started

### Prerequisites
- **Python 3.11+** (Required - tested with Python 3.11.9)
- Visual Studio Code with GitHub Copilot extension
- Basic understanding of statistical analysis concepts
- Enterprise data analysis requirements

### System Requirements
- **Python Version**: 3.11.0 or higher
- **Operating System**: Windows 10/11, macOS 10.15+, or Linux
- **Memory**: 8GB RAM minimum (16GB recommended for large datasets)
- **Storage**: 2GB free space for packages and data

### Quick Start
1. **Activate the Virtual Environment**: 
   ```bash
   .venv\Scripts\Activate.ps1
   ```

2. **Launch Jupyter Lab**:
   ```bash
   jupyter lab
   ```

3. **Activate the Cognitive Architecture**: 
   ```
   "show memory status"
   ```

4. **Begin Data Analysis Excellence**:
   ```
   "help me analyze this SPSS dataset"
   ```

## ğŸ’» Installation & Setup

### âš ï¸ Python Version Requirement
This project **requires Python 3.11 or higher**. The requirements have been specifically tested with Python 3.11.9.

**Why Python 3.11+?**
- Advanced data analysis packages require modern Python features
- Improved performance and memory management for large datasets
- Better compatibility with enterprise analytics libraries
- Future-proof architecture for emerging data science tools

### Installation Steps

1. **Verify Python Version**:
   ```bash
   python --version
   # Should show Python 3.11.x or higher
   ```

2. **Clone Repository**:
   ```bash
   git clone <repository-url>
   cd DATA-ANALYSIS
   ```

3. **Create Virtual Environment**:
   ```bash
   python -m venv .venv
   .venv\Scripts\Activate.ps1  # Windows
   # or source .venv/bin/activate  # Linux/Mac
   ```

4. **Install Requirements** (Layered Approach):
   ```bash
   # Core essentials (fast, stable)
   pip install -r requirements.txt
   
   # Advanced analytics (optional)
   pip install -r requirements-analysis.txt
   
   # Development tools (optional)
   pip install -r requirements-dev.txt
   ```

5. **Verify Installation**:
   ```bash
   python -c "import pandas as pd; import numpy as np; print('âœ… Environment ready!')"
   ```

### Requirements Structure
- **`requirements.txt`** - Core essentials (pandas, numpy, jupyter, etc.)
- **`requirements-analysis.txt`** - Advanced analytics packages
- **`requirements-dev.txt`** - Development and testing tools
- **`REQUIREMENTS-GUIDE.md`** - Detailed installation guide

## ğŸ“Š Key Features

### Data Processing Capabilities
- **SPSS Integration**: Native .sav file loading with complete metadata preservation
- **Data Quality Assessment**: Comprehensive missing data analysis and outlier detection
- **Statistical Validation**: Assumption checking and effect size calculations
- **Enterprise Security**: Data privacy and compliance protocols

### Analysis Tools
- **Descriptive Statistics**: Publication-quality summary statistics and visualizations
- **Inferential Statistics**: Hypothesis testing with proper assumption validation
- **Multivariate Analysis**: PCA, factor analysis, clustering, and classification
- **Advanced Methods**: Bayesian analysis, survival analysis, and mixed-effects modeling

### Visualization Suite
- **Publication Graphics**: High-quality static plots with customizable styling
- **Interactive Dashboards**: Real-time data exploration and stakeholder presentations
- **Statistical Plots**: Specialized visualizations for statistical analysis
- **Export Capabilities**: Multiple format support for presentations and publications

## ğŸ“ Project Structure

```
DATA-ANALYSIS/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md     # Global cognitive memory
â”‚   â”œâ”€â”€ instructions/               # Procedural memory (45+ files)
â”‚   â””â”€â”€ prompts/                    # Episodic memory (45+ files)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/               # Exploratory data analysis
â”‚   â”œâ”€â”€ modeling/                  # Statistical modeling
â”‚   â”œâ”€â”€ visualization/             # Data visualization
â”‚   â””â”€â”€ reports/                   # Final reports
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Original data files
â”‚   â”œâ”€â”€ processed/                 # Cleaned datasets
â”‚   â”œâ”€â”€ output/                    # Analysis results
â”‚   â”œâ”€â”€ sensitive/                 # Sensitive data (excluded)
â”‚   â””â”€â”€ pii/                       # PII data (excluded)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/                     # Utility functions
â”‚   â”œâ”€â”€ models/                    # Statistical models
â”‚   â”œâ”€â”€ visualization/             # Custom plotting
â”‚   â”œâ”€â”€ pipelines/                 # Data pipelines
â”‚   â””â”€â”€ validation/                # Data validation
â”œâ”€â”€ tests/                         # Test files
â”œâ”€â”€ docs/                          # Documentation
â””â”€â”€ config/                        # Configuration files
```

## ğŸ”¬ Statistical Capabilities

### Core Statistical Methods
- **Descriptive Statistics**: Mean, median, mode, variance, skewness, kurtosis
- **Hypothesis Testing**: t-tests, ANOVA, chi-square, non-parametric tests
- **Correlation Analysis**: Pearson, Spearman, partial correlations
- **Regression Analysis**: Linear, logistic, polynomial, robust regression

### Advanced Analytics
- **Multivariate Methods**: PCA, factor analysis, discriminant analysis
- **Clustering**: K-means, hierarchical, DBSCAN, mixture models
- **Time Series**: ARIMA, seasonal decomposition, forecasting
- **Machine Learning**: Classification, regression, feature selection

### Enterprise Features
- **Data Governance**: Quality monitoring, lineage tracking, compliance
- **Automated Reporting**: Scheduled analysis and dashboard updates
- **Scalable Processing**: Distributed computing for large datasets
- **Security**: Data encryption, access controls, audit trails

## ğŸ§  Meta-Cognitive Commands

### Memory Management
- `"show memory status"` - Display cognitive architecture health
- `"meditate"` - Optimize memory and consolidate learnings
- `"remember this analysis"` - Commit insights to long-term memory

### Analysis Assistance
- `"analyze this SPSS file"` - Comprehensive .sav file analysis
- `"check statistical assumptions"` - Validate analysis prerequisites
- `"create publication plots"` - Generate high-quality visualizations
- `"assess analysis quality"` - Self-evaluation of methodology

## ğŸ“š Documentation

### Core Documentation
- **[Setup Guide](SETUP-DATA-ANALYSIS.md)** - Complete installation and configuration
- **[User Manual](MANUAL-DATA-ANALYSIS.md)** - Comprehensive usage guide
- **[Enterprise Framework](IMPLEMENTATION_GUIDE.md)** - 9-point methodology

### Sample Analyses
- **[Enterprise Template](notebooks/exploratory/enterprise_analysis_template.ipynb)** - Complete analysis workflow
- **Statistical Examples** - Domain-specific analysis templates
- **Visualization Gallery** - Publication-quality plot examples

## ğŸ”§ Configuration

### Environment Variables
```bash
# Data paths
DATA_RAW_PATH=data/raw
DATA_PROCESSED_PATH=data/processed
DATA_OUTPUT_PATH=data/output

# Analysis settings
DEFAULT_SIGNIFICANCE_LEVEL=0.05
DEFAULT_CONFIDENCE_INTERVAL=0.95
MAX_MISSING_THRESHOLD=0.1

# Visualization
DEFAULT_DPI=300
DEFAULT_FIGURE_SIZE=12,8
```

### VS Code Settings
The setup includes optimized VS Code configuration for:
- Python development with type checking
- Jupyter notebook integration
- Code quality and formatting
- Statistical analysis workflows

## ğŸ¢ Enterprise Benefits

- **Professional Excellence**: AI-powered assistance enhances statistical analysis quality
- **Best Practices**: Enterprise-grade frameworks ensure methodological rigor
- **Knowledge Management**: Cognitive architecture captures and organizes statistical insights
- **Quality Assurance**: Advanced validation and compliance frameworks
- **Continuous Improvement**: Systematic approach to methodology optimization

## ğŸ”„ Maintenance

### Regular Updates
- **Weekly**: Execute self-assessment for methodology validation
- **Monthly**: Run meta-learning analysis for process optimization
- **Quarterly**: Perform cognitive architecture health checks
- **Annually**: Update statistical capabilities and enterprise standards

### Monitoring
- Statistical analysis quality metrics
- Cognitive architecture performance
- Memory utilization and optimization
- Enterprise compliance validation

## ğŸ¤ Contributing

This enterprise data analysis environment is designed for:
- Statistical analysts and data scientists
- Research organizations and universities
- Enterprise analytics teams
- Compliance-critical data environments

## ğŸ“ Support

For technical assistance with the cognitive architecture:
- Meta-cognitive questions: Use built-in help system
- Statistical methodology: Consult procedural memory files
- Enterprise integration: Review implementation guide

---

**Ready to transform your data analysis capabilities with enterprise-grade cognitive AI assistance?**

*Project Catalyst - Enterprise Data Analysis Cognitive Architecture v0.9.0*
