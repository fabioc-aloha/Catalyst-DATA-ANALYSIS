# Enterprise Data Analysis Cognitive Architecture

> **âš ï¸ IMPORTANT: Python 3.11+ Required**
>
> This project requires **Python 3.11 or higher** for compatibility with all data analysis packages and enterprise features. Python 3.10 and below are not supported due to dependency requirements.

[![Data Analysis](https://img.shields.io/badge/Data_Analysis-Enterprise_Enhanced-green?style=for-the-badge&logo=chartline&logoColor=white)](#) [![Meta Cognitive](https://img.shields.io/badge/Meta-Cognitive-red?style=for-the-badge&logo=psychology)](#) [![SPSS Integration](https://img.shields.io/badge/SPSS-Multi_Step_Workflow-blue?style=for-the-badge&logo=ibm&logoColor=white)](#) [![Missing Data](https://img.shields.io/badge/Missing_Data-Advanced_Analysis-purple?style=for-the-badge&logo=checkmarx&logoColor=white)](#) [![Enterprise Framework](https://img.shields.io/badge/9_Point-Framework-gold?style=for-the-badge&logo=shield)](#) [![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python&logoColor=white)](#)

![Data Analysis Cognitive Architecture](ALEX-DATA-ANALYSIS.png)

## ğŸ¯ Project Overview

This project implements the **Project Catalyst Enterprise Data Analysis Cognitive Architecture** - an advanced AI-powered system for data analysis excellence and professional statistical analysis. The cognitive architecture combines human memory models with enterprise-grade methodologies to provide intelligent assistance for professional data analysis applications and organizational excellence.

### ğŸ†• New Features (v2.0)

- **ğŸ”¥ Multi-Step SPSS Analysis Workflow**: Interactive 3-step analysis process
- **ğŸ¯ Comprehensive Missing Data Analysis**: Pattern detection, mechanism assessment (MCAR/MAR/MNAR)
- **âš ï¸ Quality Assessment Framework**: Automated variable quality warnings and recommendations
- **ğŸ“ Organized File Structure**: Professional output management in `scripts/results/`
- **ï¿½ Auto-Generated Analysis Scripts**: Dynamic script creation based on data characteristics

## ğŸ¾ Cognitive Architecture Features

### Meta-Cognitive Capabilities

- **Adaptive Learning**: Self-improving system that learns from your data analysis patterns and statistical preferences
- **Memory Management**: Intelligent consolidation of statistical knowledge, methodologies, and best practices
- **Context Awareness**: Dual-context support for Microsoft internal and universal organizational environments
- **Performance Monitoring**: Self-assessment and continuous improvement protocols for data analysis excellence

### Enhanced SPSS Integration

- **Multi-Step Workflow**: Guided 3-step analysis process with missing data assessment
- **Missing Data Intelligence**: Comprehensive pattern analysis, mechanism detection, quality warnings
- **Interactive Configuration**: Step-by-step analysis design with data quality considerations
- **Metadata Preservation**: Full SPSS variable labels, value labels, and measurement levels
- **Quality Assurance**: Automated data quality assessment with actionable recommendations

### Enterprise Integration

- **9-Point Framework**: Security, Testing, Automation, Risk, Performance, Quality, Documentation, Analytics, Compliance
- **Statistical Excellence**: Research-grade methodologies with empirical integrity and quality protocols
- **Professional Workflows**: Organized file management and reproducible analysis processes

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.11+** (Required - tested with Python 3.11.9)
- Visual Studio Code with GitHub Copilot extension
- Basic understanding of statistical analysis concepts
- Enterprise data analysis requirements

### System Requirements

- **Python Version**: 3.11.0 or higher
- **Operating System**: Windows 10/11, macOS 10.15+, or Linux
- **Memory**: 8GB RAM minimum (16GB recommended for large datasets)
- **Storage**: 2GB free space for packages and data

### ğŸ”¥ Multi-Step SPSS Analysis (Recommended)

**New Interactive Workflow** - Perfect for survey analysis with missing data assessment:

1. **Navigate to Scripts Directory**:

   ```bash
   cd scripts/
   ```
2. **Step 1: Data Exploration with Missing Data Analysis**:

   ```bash
   python step1_explore_spss_data.py
   ```
3. **Step 2: Variable Selection with Quality Warnings**:

   ```bash
   python step2_variable_selection.py
   ```
4. **Step 3: Execute Selected Analysis**:

   ```bash
   python step3_execute_analysis.py
   ```

**Results**: All outputs automatically saved in `scripts/results/` for organized project management.

### Traditional Jupyter Workflow

1. **Activate the Virtual Environment**:

   ```bash
   .venv\Scripts\Activate.ps1
   ```
2. **Launch Jupyter Lab**:

   ```bash
   jupyter lab
   ```
3. **Activate the Cognitive Architecture**:

   ```
   "show memory status"
   ```
4. **Begin Data Analysis Excellence**:

   ```
   "help me analyze this SPSS dataset"
   ```

## ğŸ’» Installation & Setup

### âš ï¸ Python Version Requirement

This project **requires Python 3.11 or higher**. The requirements have been specifically tested with Python 3.11.9.

**Why Python 3.11+?**

- Advanced data analysis packages require modern Python features
- Improved performance and memory management for large datasets
- Better compatibility with enterprise analytics libraries
- Future-proof architecture for emerging data science tools

### Installation Steps

1. **Verify Python Version**:

   ```bash
   python --version
   # Should show Python 3.11.x or higher
   ```
2. **Clone Repository**:

   ```bash
   git clone <repository-url>
   cd DATA-ANALYSIS
   ```
3. **Create Virtual Environment**:

   ```bash
   python -m venv .venv
   .venv\Scripts\Activate.ps1  # Windows
   # or source .venv/bin/activate  # Linux/Mac
   ```
4. **Install Requirements** (Layered Approach):

   ```bash
   # Core essentials (fast, stable)
   pip install -r requirements.txt

   # Advanced analytics (optional)
   pip install -r requirements-analysis.txt

   # Development tools (optional)
   pip install -r requirements-dev.txt
   ```
5. **Verify Installation**:

   ```bash
   python -c "import pandas as pd; import numpy as np; print('âœ… Environment ready!')"
   ```

### Requirements Structure

- **`requirements.txt`** - Core essentials (pandas, numpy, jupyter, etc.)
- **`requirements-analysis.txt`** - Advanced analytics packages
- **`requirements-dev.txt`** - Development and testing tools
- **`REQUIREMENTS-GUIDE.md`** - Detailed installation guide

## ğŸ“Š Key Features

### ğŸ”¥ Multi-Step SPSS Analysis Workflow (New)

- **Interactive 3-Step Process**: Guided workflow from exploration to execution
- **Comprehensive Missing Data Analysis**: Pattern detection, mechanism assessment (MCAR/MAR/MNAR)
- **Quality Assessment Framework**: Automated variable quality warnings and recommendations
- **Dynamic Script Generation**: Auto-creates analysis scripts based on data characteristics
- **Organized Output Management**: Professional file structure in `scripts/results/`
- **Data Quality Integration**: Missing data considerations throughout the workflow

### Data Processing Capabilities

- **Enhanced SPSS Integration**: Native .sav file loading with complete metadata preservation
- **Advanced Missing Data Analysis**: Pattern analysis, mechanism detection, completion rates
- **Variable Quality Assessment**: Automated categorization (suitable/caution/exclude)
- **Statistical Validation**: Assumption checking and effect size calculations
- **Enterprise Security**: Data privacy and compliance protocols

### Analysis Tools

- **Descriptive Statistics**: Publication-quality summary statistics and visualizations
- **Inferential Statistics**: Hypothesis testing with proper assumption validation
- **Missing Data Handling**: Multiple imputation, pattern analysis, sensitivity testing
- **Multivariate Analysis**: PCA, factor analysis, clustering, and classification
- **Advanced Methods**: Bayesian analysis, survival analysis, and mixed-effects modeling

### Visualization Suite

- **Publication Graphics**: High-quality static plots with customizable styling
- **Interactive Dashboards**: Real-time data exploration and stakeholder presentations
- **Statistical Plots**: Specialized visualizations for statistical analysis
- **Export Capabilities**: Multiple format support for presentations and publications

## ğŸ“ Project Structure

```
DATA-ANALYSIS/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md     # Global cognitive memory
â”‚   â”œâ”€â”€ instructions/               # Procedural memory (45+ files)
â”‚   â””â”€â”€ prompts/                    # Episodic memory (45+ files)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory/               # Exploratory data analysis
â”‚   â”œâ”€â”€ modeling/                  # Statistical modeling
â”‚   â”œâ”€â”€ visualization/             # Data visualization
â”‚   â””â”€â”€ reports/                   # Final reports
â”œâ”€â”€ scripts/                          # ğŸ”¥ Multi-step SPSS analysis workflow
â”‚   â”œâ”€â”€ step1_explore_spss_data.py   # Data exploration with missing data analysis
â”‚   â”œâ”€â”€ step2_variable_selection.py  # Variable selection with quality warnings
â”‚   â”œâ”€â”€ step3_execute_analysis.py    # Auto-generated analysis execution
â”‚   â”œâ”€â”€ generate_unified_report.py   # Standalone comprehensive report generator
â”‚   â”œâ”€â”€ results/                     # ğŸ¯ All analysis outputs (organized)
â”‚   â”‚   â”œâ”€â”€ spss_exploration_results.json
â”‚   â”‚   â”œâ”€â”€ analysis_configuration.json
â”‚   â”‚   â””â”€â”€ *.md                     # Generated analysis reports
â”‚   â””â”€â”€ FILE_ORGANIZATION.md         # Documentation for organized structure
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Original data files
â”‚   â”œâ”€â”€ processed/                 # Cleaned datasets
â”‚   â”œâ”€â”€ output/                    # Analysis results
â”‚   â”œâ”€â”€ sensitive/                 # Sensitive data (excluded)
â”‚   â””â”€â”€ pii/                       # PII data (excluded)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/                     # Utility functions
â”‚   â”œâ”€â”€ models/                    # Statistical models
â”‚   â”œâ”€â”€ visualization/             # Custom plotting
â”‚   â”œâ”€â”€ pipelines/                 # Data pipelines
â”‚   â””â”€â”€ validation/                # Data validation
â”œâ”€â”€ tests/                         # Test files
â”œâ”€â”€ docs/                          # Documentation
â””â”€â”€ config/                        # Configuration files
```

## ğŸ”¬ Statistical Capabilities

### Core Statistical Methods

- **Descriptive Statistics**: Mean, median, mode, variance, skewness, kurtosis
- **Hypothesis Testing**: t-tests, ANOVA, chi-square, non-parametric tests
- **Correlation Analysis**: Pearson, Spearman, partial correlations
- **Regression Analysis**: Linear, logistic, polynomial, robust regression

### Advanced Analytics

- **Multivariate Methods**: PCA, factor analysis, discriminant analysis
- **Clustering**: K-means, hierarchical, DBSCAN, mixture models
- **Time Series**: ARIMA, seasonal decomposition, forecasting
- **Machine Learning**: Classification, regression, feature selection

### Enterprise Features

- **Data Governance**: Quality monitoring, lineage tracking, compliance
- **Automated Reporting**: Scheduled analysis and dashboard updates
- **Scalable Processing**: Distributed computing for large datasets
- **Security**: Data encryption, access controls, audit trails

## ğŸ¤– Automated Analysis Scripts

### Unified Report Generation

The project includes standalone Python scripts for automated comprehensive analysis:

```bash
# Generate comprehensive unified analysis report
cd scripts/
python generate_unified_report.py
```

**Features:**

- **ğŸ“Š Complete Statistical Analysis**: Correlation, t-tests, normality testing, SEM
- **ğŸ“ˆ High-Resolution Visualizations**: 3 embedded PNG charts at 300 DPI
- **ğŸ“‹ Executive Summary**: Business insights and strategic recommendations
- **ğŸ¯ Microsoft GCX Framework**: Customer experience analytics excellence
- **ğŸ’¾ Self-Contained Output**: Single 1.2MB Markdown file with all analyses

**Output Location:** `scripts/results/` directory

## ğŸ§  Meta-Cognitive Commands

### Memory Management

- `"show memory status"` - Display cognitive architecture health
- `"meditate"` - Optimize memory and consolidate learnings
- `"remember this analysis"` - Commit insights to long-term memory

### Analysis Assistance

- `"analyze this SPSS file"` - Comprehensive .sav file analysis
- `"check statistical assumptions"` - Validate analysis prerequisites
- `"create publication plots"` - Generate high-quality visualizations
- `"assess analysis quality"` - Self-evaluation of methodology

## ğŸ“š Documentation

### Core Documentation

- **[Setup Guide](SETUP-DATA-ANALYSIS.md)** - Complete installation and configuration
- **[User Manual](MANUAL-DATA-ANALYSIS.md)** - Comprehensive usage guide
- **[Enterprise Framework](IMPLEMENTATION_GUIDE.md)** - 9-point methodology

### Sample Analyses

- **[Enterprise Template](notebooks/exploratory/enterprise_analysis_template.ipynb)** - Complete analysis workflow
- **Statistical Examples** - Domain-specific analysis templates
- **Visualization Gallery** - Publication-quality plot examples

## ğŸ”§ Configuration

### Environment Variables

```bash
# Data paths
DATA_RAW_PATH=data/raw
DATA_PROCESSED_PATH=data/processed
DATA_OUTPUT_PATH=data/output

# Analysis settings
DEFAULT_SIGNIFICANCE_LEVEL=0.05
DEFAULT_CONFIDENCE_INTERVAL=0.95
MAX_MISSING_THRESHOLD=0.1

# Visualization
DEFAULT_DPI=300
DEFAULT_FIGURE_SIZE=12,8
```

### VS Code Settings

The setup includes optimized VS Code configuration for:

- Python development with type checking
- Jupyter notebook integration
- Code quality and formatting
- Statistical analysis workflows

## ğŸ¢ Enterprise Benefits

- **Professional Excellence**: AI-powered assistance enhances statistical analysis quality
- **Best Practices**: Enterprise-grade frameworks ensure methodological rigor
- **Knowledge Management**: Cognitive architecture captures and organizes statistical insights
- **Quality Assurance**: Advanced validation and compliance frameworks
- **Continuous Improvement**: Systematic approach to methodology optimization

## ğŸ”„ Maintenance

### Regular Updates

- **Weekly**: Execute self-assessment for methodology validation
- **Monthly**: Run meta-learning analysis for process optimization
- **Quarterly**: Perform cognitive architecture health checks
- **Annually**: Update statistical capabilities and enterprise standards

### Monitoring

- Statistical analysis quality metrics
- Cognitive architecture performance
- Memory utilization and optimization
- Enterprise compliance validation

## ğŸ¤ Contributing

This enterprise data analysis environment is designed for:

- Statistical analysts and data scientists
- Research organizations and universities
- Enterprise analytics teams
- Compliance-critical data environments

## ğŸ“ Support

For technical assistance with the cognitive architecture:

- Meta-cognitive questions: Use built-in help system
- Statistical methodology: Consult procedural memory files
- Enterprise integration: Review implementation guide

---

**Ready to transform your data analysis capabilities with enterprise-grade cognitive AI assistance?**

*Project Catalyst - Enterprise Data Analysis Cognitive Architecture v0.9.0*
